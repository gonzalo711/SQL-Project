{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05185042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#school_id=84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edfaddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 1070\n"
     ]
    }
   ],
   "source": [
    "#Get text\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the span tag with the specified class\n",
    "span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "\n",
    "# Extract the text content\n",
    "if span_tag:\n",
    "    reviews_text = span_tag.get_text(strip=True)\n",
    "    reviews_match = re.search(r'(\\d+)', reviews_text)\n",
    "    if reviews_match:\n",
    "        number_of_reviews = reviews_match.group(1)\n",
    "        print(f\"Number of reviews: {number_of_reviews}\")\n",
    "    else:\n",
    "        print(\"No reviews found.\")\n",
    "else:\n",
    "    print(\"Span tag not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59db5f27",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Rating not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m extract_rating(soup)\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mextract_rating\u001b[0;34m(html_content)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_rating\u001b[39m(html_content):\n\u001b[0;32m----> 3\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html_content, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Find the span tag with the specified class for reviews\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     span_tag \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-orange-dark font-semibold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:314\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;241m=\u001b[39m parse_only\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):        \u001b[38;5;66;03m# It's a file-type object.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     markup \u001b[38;5;241m=\u001b[39m markup\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(markup) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    316\u001b[0m         (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_markup_is_url(markup):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "#Extract rating\n",
    "def extract_rating(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the span tag with the specified class for reviews\n",
    "    span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "\n",
    "    # Extract the text content for reviews\n",
    "    if span_tag:\n",
    "        reviews_text = span_tag.get_text(strip=True)\n",
    "        print(f\"Number of reviews: {reviews_text}\")\n",
    "    else:\n",
    "        print(\"Span tag for reviews not found.\")\n",
    "\n",
    "    # Find the span element with the text \"Average Rating\"\n",
    "    average_rating_span = soup.find('span', text='Average Rating')\n",
    "\n",
    "    # Extract the text content of the following sibling span (containing the rating)\n",
    "    if average_rating_span:\n",
    "        rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "        print(f\"Average Rating: {rating}\")\n",
    "    else:\n",
    "        print(\"Average Rating not found.\")\n",
    "        \n",
    "extract_rating(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a44a9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 1070Reviews\n",
      "Average Rating: 4.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/3681854451.py:18: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_rating(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Find the span tag with the specified class for reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "\n",
    "        # Extract the text content for reviews\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Find the span element with the text \"Average Rating\"\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "\n",
    "        # Extract the text content of the following sibling span (containing the rating)\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_rating(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0e5c6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span tag for reviews not found.\n",
      "Average Rating not found.\n",
      "Cities: ['Amsterdam', 'Barcelona', 'Berlin', 'Lisbon', 'Madrid', 'Miami', 'Online', 'Paris']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/662294493.py:16: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_school_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract number of reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div')\n",
    "        if locations_div:\n",
    "            # Find <a> elements inside the locations_div\n",
    "            locations = locations_div.find_all('a')\n",
    "            \n",
    "            if locations:\n",
    "                cities_list = [location.get_text(strip=True) for location in locations]\n",
    "                print(f\"Cities: {cities_list}\")\n",
    "            else:\n",
    "                print(\"No cities found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example HTML structure\n",
    "html_content = '<div><a href=\"/cities/amsterdam\">Amsterdam</a>, <a href=\"/cities/barcelona\">Barcelona</a>, <a href=\"/cities/berlin\">Berlin</a>, <a href=\"/cities/lisbon\">Lisbon</a>, <a href=\"/cities/madrid\">Madrid</a>, <a href=\"/cities/miami-coding-bootcamps\">Miami</a>, <a href=\"/cities/online-coding-bootcamps\">Online</a>, <a href=\"/cities/paris\">Paris</a></div>'\n",
    "\n",
    "extract_school_info(html_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4489b44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 1070Reviews\n",
      "Average Rating: 4.79\n",
      "Cities: ['', 'Get Matched', 'All Schools', 'Exclusive Scholarships', 'Full Stack Developer', 'Mobile App Development', 'Front End Developer', 'Data Science', 'UX Design', 'Digital Marketing', 'Product Manager', 'Cyber Security', 'Tech Sales', 'Machine Learning & AI', 'All Articles', 'Ultimate Guide: Bootcamps In 2023', 'Best Coding Bootcamps', 'Best Data Science Bootcamps', 'Best UI/UX Design Bootcamps', 'Best Cybersecurity Bootcamps', 'Best Online Bootcamps', 'Best Tech Sales Bootcamps', 'Best Digital Marketing Bootcamps', 'Best Product Management Bootcamps', 'Best QA Testing Bootcamps', 'Write a Review', 'Get Matched', 'Sign In']\n",
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1972914274.py:17: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_school_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract number of reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div')\n",
    "        if locations_div:\n",
    "            # Find <a> elements inside the locations_div\n",
    "            locations = locations_div.find_all('a')\n",
    "            \n",
    "            if locations:\n",
    "                cities_list = [location.get_text(strip=True) for location in locations]\n",
    "                print(f\"Cities: {cities_list}\")\n",
    "            else:\n",
    "                print(\"No cities found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_school_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6520beb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2699332864.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    <span>4.79</span>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<div class=\"flex gap-3 text-gray-dark\"><span>Average Rating</span><span>4.79</span><span class=\"flex\"><svg viewBox=\"0 0 24 24\" class=\"fill-current text-orange w-4 h-4 \"><path d=\"M12 .587l3.668 7.568L24 9.306l-6.064 5.828 1.48 8.279L12 19.446l-7.417 3.967 1.481-8.279L0 9.306l8.332-1.151z\"></path></svg><svg viewBox=\"0 0 24 24\" class=\"fill-current text-orange w-4 h-4 \"><path d=\"M12 .587l3.668 7.568L24 9.306l-6.064 5.828 1.48 8.279L12 19.446l-7.417 3.967 1.481-8.279L0 9.306l8.332-1.151z\"></path></svg><svg viewBox=\"0 0 24 24\" class=\"fill-current text-orange w-4 h-4 \"><path d=\"M12 .587l3.668 7.568L24 9.306l-6.064 5.828 1.48 8.279L12 19.446l-7.417 3.967 1.481-8.279L0 9.306l8.332-1.151z\"></path></svg><svg viewBox=\"0 0 24 24\" class=\"fill-current text-orange w-4 h-4 \"><path d=\"M12 .587l3.668 7.568L24 9.306l-6.064 5.828 1.48 8.279L12 19.446l-7.417 3.967 1.481-8.279L0 9.306l8.332-1.151z\"></path></svg><svg viewBox=\"0 0 24 24\" class=\"fill-current text-orange w-4 h-4 \"><path d=\"M12 5.173l2.335 4.817 5.305.732-3.861 3.71.942 5.27L12 17.178V5.173zm0-4.586L8.332 8.155 0 9.306l6.064 5.828-1.48 8.279L12 19.446l7.416 3.966-1.48-8.279L24 9.306l-8.332-1.15L12 .587z\"></path></svg></span></div>\n",
    "<span>4.79</span>\n",
    "<span>Average Rating</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0d2d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'average_rating_span' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the text content of the following sibling span (containing the rating)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average_rating_span:\n\u001b[1;32m      3\u001b[0m     rating \u001b[38;5;241m=\u001b[39m average_rating_span\u001b[38;5;241m.\u001b[39mfind_next_sibling(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msoup(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Rating for a school: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrating\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'average_rating_span' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the text content of the following sibling span (containing the rating)\n",
    "if average_rating_span:\n",
    "    rating = average_rating_span.find_next_sibling('span').soup(strip=True)\n",
    "    print(f\"Average Rating for a school: {rating}\")\n",
    "else:\n",
    "    print(\"Average Rating not found for a school.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "256f2a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span tag for reviews not found.\n",
      "Average Rating not found.\n",
      "Cities: ['Amsterdam', 'Barcelona', 'Berlin', 'Lisbon', 'Madrid', 'Miami', 'Online', 'Paris']\n",
      "Course Names: ['Cyber Security Bootcamp (Full-time)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/406073436.py:16: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 1070Reviews\n",
      "Average Rating: 4.79\n",
      "Cities: ['Get MatchedBrowse SchoolsAll SchoolsExclusive ScholarshipsCareer TracksFull Stack DeveloperMobile App DevelopmentFront End DeveloperData ScienceUX DesignDigital MarketingProduct ManagerCyber SecurityTech SalesMachine Learning & AIAdviceAll ArticlesBootcamp RankingsUltimate Guide: Bootcamps In 2023Best Coding BootcampsBest Data Science BootcampsBest UI/UX Design BootcampsBest Cybersecurity BootcampsBest Online BootcampsBest Tech Sales BootcampsBest Digital Marketing BootcampsBest Product Management BootcampsBest QA Testing BootcampsWrite a ReviewGet MatchedSign In']\n",
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_school_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract number of reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div')\n",
    "        if locations_div:\n",
    "            # Extract the entire content of the locations_div\n",
    "            locations_content = locations_div.get_text(strip=True)\n",
    "\n",
    "            # Split the content by commas to get a list of cities\n",
    "            cities_list = [city.strip() for city in locations_content.split(',')]\n",
    "            \n",
    "            if cities_list:\n",
    "                print(f\"Cities: {cities_list}\")\n",
    "            else:\n",
    "                print(\"No cities found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example HTML structure containing cities and course titles\n",
    "html_content = '''\n",
    "<div><a href=\"/cities/amsterdam\">Amsterdam</a>, <a href=\"/cities/barcelona\">Barcelona</a>, <a href=\"/cities/berlin\">Berlin</a>, <a href=\"/cities/lisbon\">Lisbon</a>, <a href=\"/cities/madrid\">Madrid</a>, <a href=\"/cities/miami-coding-bootcamps\">Miami</a>, <a href=\"/cities/online-coding-bootcamps\">Online</a>, <a href=\"/cities/paris\">Paris</a></div>\n",
    "<div class=\"flex justify-between items-center\" data-action=\"click->toggle#toggle\">\n",
    "    <h3 class=\"font-semibold text-lg md:text-xl my-4 md:my-0\" data-ga=\"card-title\">Cyber Security Bootcamp (Full-time)</h3>\n",
    "    <div class=\"md:hidden\" data-toggle-target=\"content\"><svg xmlns=\"http://www.w3.org/2000/svg\" class=\"h-6 w-6\" fill=\"none\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M12 4v16m8-8H4\"></path></svg></div>\n",
    "    <div class=\"md:hidden hidden\" data-toggle-target=\"content\"><svg xmlns=\"http://www.w3.org/2000/svg\" class=\"h-6 w-6\" fill=\"none\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M20 12H4\"></path></svg></div>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "extract_school_info(html_content)\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_school_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16473d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 3062Reviews\n",
      "Average Rating: 4.96\n",
      "Cities: ['Amsterdam', 'Bali', 'Barcelona', 'Berlin', 'Bordeaux', 'Brussels', 'Buenos Aires', 'Cape Town', 'Casablanca', 'Cologne', 'Dubai', 'Lausanne', 'Lille', 'Lisbon', 'London', 'Lyon', 'Madrid', 'Marseille', 'Mauritius', 'Melbourne', 'Mexico City', 'Montreal', 'Munich', 'Nantes', 'Nice', 'Online', 'Paris', 'Porto', 'Rennes', 'Rio de Janeiro', 'Santiago', 'Sao Paulo', 'Shanghai', 'Singapore', 'Sydney', 'Tokyo', 'Toulouse', 'Zurich']\n",
      "Course Names: ['Data Analytics Bootcamp', 'Data Analytics Bootcamp Online', 'Data Analytics Essentials Skill Course', 'Data Engineering Bootcamp', 'Data Engineering Bootcamp Online', 'Data Science & AI Bootcamp - Full-time', 'Data Science & AI Bootcamp Online', 'Data Science & AI Bootcamp - Part-time', 'Data Science & AI Bootcamp - Part-time Online', 'Growth & Data Automation Skill Course', 'Python & Machine Learning Skill Course', 'Web Analytics & Tracking Skill Course', 'Web Development Bootcamp - Full-time', 'Web Development Bootcamp Online', 'Web Development Bootcamp - Part-time', 'Web Development Bootcamp - Part-time Online']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/4086301591.py:27: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/4086301591.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n"
     ]
    }
   ],
   "source": [
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/le-wagon'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_school_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_school_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract number of reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                    print(f\"Cities: {cities_list}\")\n",
    "                else:\n",
    "                    print(\"No cities found.\")\n",
    "            else:\n",
    "                print(\"Cities div not found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4225d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 3062Reviews\n",
      "Average Rating: 4.96\n",
      "Cities: ['Amsterdam', 'Bali', 'Barcelona', 'Berlin', 'Bordeaux', 'Brussels', 'Buenos Aires', 'Cape Town', 'Casablanca', 'Cologne', 'Dubai', 'Lausanne', 'Lille', 'Lisbon', 'London', 'Lyon', 'Madrid', 'Marseille', 'Mauritius', 'Melbourne', 'Mexico City', 'Montreal', 'Munich', 'Nantes', 'Nice', 'Online', 'Paris', 'Porto', 'Rennes', 'Rio de Janeiro', 'Santiago', 'Sao Paulo', 'Shanghai', 'Singapore', 'Sydney', 'Tokyo', 'Toulouse', 'Zurich']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/891736744.py:20: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/891736744.py:28: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Name: Cyber Security Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Cyber Security Bootcamp (Part-time)\n",
      "Price not found.\n",
      "Course Name: Data Analytics Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Data Analytics Bootcamp (Part-Time)\n",
      "Price not found.\n",
      "Course Name: UX/UI Design Bootcamp (Full-Time)\n",
      "Price not found.\n",
      "Course Name: UX/UI Design Bootcamp (Part-Time)\n",
      "Price not found.\n",
      "Course Name: Web Development Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Web Development Bootcamp (Part-Time)\n",
      "Price not found.\n"
     ]
    }
   ],
   "source": [
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/le-wagon'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_school_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_school_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract number of reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                    print(f\"Cities: {cities_list}\")\n",
    "                else:\n",
    "                    print(\"No cities found.\")\n",
    "            else:\n",
    "                print(\"Cities div not found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "        # Extract course prices\n",
    "        price_tags = soup.find_all('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n",
    "        if price_tags:\n",
    "            prices = [tag.find_next('td').get_text(strip=True) for tag in price_tags]\n",
    "            print(f\"Course Prices: {prices}\")\n",
    "        else:\n",
    "            print(\"No prices found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b8d978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 3062Reviews\n",
      "Average Rating: 4.96\n",
      "Cities: ['Amsterdam', 'Bali', 'Barcelona', 'Berlin', 'Bordeaux', 'Brussels', 'Buenos Aires', 'Cape Town', 'Casablanca', 'Cologne', 'Dubai', 'Lausanne', 'Lille', 'Lisbon', 'London', 'Lyon', 'Madrid', 'Marseille', 'Mauritius', 'Melbourne', 'Mexico City', 'Montreal', 'Munich', 'Nantes', 'Nice', 'Online', 'Paris', 'Porto', 'Rennes', 'Rio de Janeiro', 'Santiago', 'Sao Paulo', 'Shanghai', 'Singapore', 'Sydney', 'Tokyo', 'Toulouse', 'Zurich']\n",
      "Course Names: ['Data Analytics Bootcamp', 'Data Analytics Bootcamp Online', 'Data Analytics Essentials Skill Course', 'Data Engineering Bootcamp', 'Data Engineering Bootcamp Online', 'Data Science & AI Bootcamp - Full-time', 'Data Science & AI Bootcamp Online', 'Data Science & AI Bootcamp - Part-time', 'Data Science & AI Bootcamp - Part-time Online', 'Growth & Data Automation Skill Course', 'Python & Machine Learning Skill Course', 'Web Analytics & Tracking Skill Course', 'Web Development Bootcamp - Full-time', 'Web Development Bootcamp Online', 'Web Development Bootcamp - Part-time', 'Web Development Bootcamp - Part-time Online']\n",
      "No prices found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/121082119.py:27: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/121082119.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/121082119.py:61: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  price_tags = soup.find_all('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n"
     ]
    }
   ],
   "source": [
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/le-wagon'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_school_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_school_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract number of reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                    print(f\"Cities: {cities_list}\")\n",
    "                else:\n",
    "                    print(\"No cities found.\")\n",
    "            else:\n",
    "                print(\"Cities div not found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "        # Extract course names and prices\n",
    "        course_blocks = soup.find_all('div', class_='lg:border lg:border-gray lg:p-6 p-3 bg-gray-light')\n",
    "        for course_block in course_blocks:\n",
    "            course_title = course_block.find('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "            if course_title:\n",
    "                course_name = course_title.get_text(strip=True)\n",
    "                print(f\"Course Name: {course_name}\")\n",
    "\n",
    "                # Extract course price\n",
    "                price_tag = course_block.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n",
    "                if price_tag:\n",
    "                    price = price_tag.find_next('td').get_text(strip=True)\n",
    "                    print(f\"Course Price: {price}\")\n",
    "                else:\n",
    "                    print(\"Price not found.\")\n",
    "            else:\n",
    "                print(\"Course title not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc2bb0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (4.15.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/gonzalo/anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Course Name: Cyber Security Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Cyber Security Bootcamp (Part-time)\n",
      "Price not found.\n",
      "Course Name: Data Analytics Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Data Analytics Bootcamp (Part-Time)\n",
      "Price not found.\n",
      "Course Name: UX/UI Design Bootcamp (Full-Time)\n",
      "Price not found.\n",
      "Course Name: UX/UI Design Bootcamp (Part-Time)\n",
      "Price not found.\n",
      "Course Name: Web Development Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Web Development Bootcamp (Part-Time)\n",
      "Price not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/2567112213.py:30: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  price_tag = course_block.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_prices_with_selenium(url):\n",
    "    driver = webdriver.Chrome()  # You may need to download and specify the path to your webdriver\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Wait for the prices to be loaded (adjust the timeout if needed)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'font-semibold')))\n",
    "\n",
    "        # Extract prices from the updated HTML\n",
    "        html_content = driver.page_source\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names and prices\n",
    "        course_blocks = soup.find_all('div', class_='lg:border lg:border-gray lg:p-6 p-3 bg-gray-light')\n",
    "        for course_block in course_blocks:\n",
    "            course_title = course_block.find('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "            if course_title:\n",
    "                course_name = course_title.get_text(strip=True)\n",
    "                print(f\"Course Name: {course_name}\")\n",
    "\n",
    "                # Extract course price\n",
    "                price_tag = course_block.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n",
    "                if price_tag:\n",
    "                    price = price_tag.find_next('td').get_text(strip=True)\n",
    "                    print(f\"Course Price: {price}\")\n",
    "                else:\n",
    "                    print(\"Price not found.\")\n",
    "            else:\n",
    "                print(\"Course title not found.\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "extract_prices_with_selenium(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ac80aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 1070Reviews\n",
      "Average Rating: 4.79\n",
      "Cities: ['Amsterdam', 'Barcelona', 'Berlin', 'Lisbon', 'Madrid', 'Miami', 'Online', 'Paris']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1983196871.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1983196871.py:41: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Name: Cyber Security Bootcamp (Full-time)\n",
      "Cost label not found.\n",
      "Course Name: Cyber Security Bootcamp (Part-time)\n",
      "Cost label not found.\n",
      "Course Name: Data Analytics Bootcamp (Full-time)\n",
      "Cost label not found.\n",
      "Course Name: Data Analytics Bootcamp (Part-Time)\n",
      "Cost label not found.\n",
      "Course Name: UX/UI Design Bootcamp (Full-Time)\n",
      "Cost label not found.\n",
      "Course Name: UX/UI Design Bootcamp (Part-Time)\n",
      "Cost label not found.\n",
      "Course Name: Web Development Bootcamp (Full-time)\n",
      "Cost label not found.\n",
      "Course Name: Web Development Bootcamp (Part-Time)\n",
      "Cost label not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1983196871.py:86: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  cost_label = course_block.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_school_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_school_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract number of reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                    print(f\"Cities: {cities_list}\")\n",
    "                else:\n",
    "                    print(\"No cities found.\")\n",
    "            else:\n",
    "                print(\"Cities div not found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "        # Use Selenium to extract prices\n",
    "        extract_prices_with_selenium()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "def extract_prices_with_selenium():\n",
    "    url = 'https://www.coursereport.com/schools/ironhack'\n",
    "    driver = webdriver.Chrome()  # You may need to download and specify the path to your webdriver\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Wait for the prices to be loaded (adjust the timeout if needed)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'font-semibold')))\n",
    "\n",
    "        # Extract prices from the updated HTML\n",
    "        html_content = driver.page_source\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names and prices\n",
    "        course_blocks = soup.find_all('div', class_='lg:border lg:border-gray lg:p-6 p-3 bg-gray-light')\n",
    "        for course_block in course_blocks:\n",
    "            course_title = course_block.find('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "            if course_title:\n",
    "                course_name = course_title.get_text(strip=True)\n",
    "                print(f\"Course Name: {course_name}\")\n",
    "\n",
    "                # Extract course price directly from the outer HTML\n",
    "                price_info = course_block.find('tr', class_='align-text-top', string='Cost')\n",
    "                if price_info:\n",
    "                    price = price_info.find_next('td').get_text(strip=True)\n",
    "                    print(f\"Course Price: {price}\")\n",
    "                else:\n",
    "                    print(\"Price not found.\")             \n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f6a27d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 1070Reviews\n",
      "Average Rating: 4.79\n",
      "Cities: ['Amsterdam', 'Barcelona', 'Berlin', 'Lisbon', 'Madrid', 'Miami', 'Online', 'Paris']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/891736744.py:20: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/891736744.py:28: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Name: Cyber Security Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Cyber Security Bootcamp (Part-time)\n",
      "Price not found.\n",
      "Course Name: Data Analytics Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Data Analytics Bootcamp (Part-Time)\n",
      "Price not found.\n",
      "Course Name: UX/UI Design Bootcamp (Full-Time)\n",
      "Price not found.\n",
      "Course Name: UX/UI Design Bootcamp (Part-Time)\n",
      "Price not found.\n",
      "Course Name: Web Development Bootcamp (Full-time)\n",
      "Price not found.\n",
      "Course Name: Web Development Bootcamp (Part-Time)\n",
      "Price not found.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def extract_school_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract number of reviews\n",
    "        span_tag = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if span_tag:\n",
    "            reviews_text = span_tag.get_text(strip=True)\n",
    "            print(f\"Number of reviews: {reviews_text}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "\n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "            print(f\"Average Rating: {rating}\")\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                    print(f\"Cities: {cities_list}\")\n",
    "                else:\n",
    "                    print(\"No cities found.\")\n",
    "            else:\n",
    "                print(\"Cities div not found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "        # Use Selenium to extract prices\n",
    "        extract_prices_with_selenium()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "def extract_prices_with_selenium():\n",
    "    url = 'https://www.coursereport.com/schools/ironhack'\n",
    "    driver = webdriver.Chrome()  # You may need to download and specify the path to your webdriver\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Wait for the prices to be loaded (adjust the timeout if needed)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'font-semibold')))\n",
    "\n",
    "        # Extract prices from the updated HTML\n",
    "        html_content = driver.page_source\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names and prices\n",
    "        course_blocks = soup.find_all('div', class_='lg:border lg:border-gray lg:p-6 p-3 bg-gray-light')\n",
    "        for course_block in course_blocks:\n",
    "            course_title = course_block.find('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "            if course_title:\n",
    "                course_name = course_title.get_text(strip=True)\n",
    "                print(f\"Course Name: {course_name}\")\n",
    "\n",
    "                # Extract course price directly from the outer HTML\n",
    "                price_info = course_block.find('tr', class_='align-text-top', string='Cost')\n",
    "                if price_info:\n",
    "                    price = price_info.find_next('td').get_text(strip=True)\n",
    "                    print(f\"Course Price: {price}\")\n",
    "                else:\n",
    "                    # Try an alternative method to find the price\n",
    "                    price_td = course_block.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', string='Cost')\n",
    "                    if price_td:\n",
    "                        price = price_td.find_next('td').get_text(strip=True)\n",
    "                        print(f\"Course Price: {price}\")\n",
    "                    else:\n",
    "                        print(\"Price not found.\")\n",
    "            else:\n",
    "                print(\"Course title not found.\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_school_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afc986c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 1070Reviews\n",
      "Average Rating: 4.79\n",
      "Cities: ['Amsterdam', 'Barcelona', 'Berlin', 'Lisbon', 'Madrid', 'Miami', 'Online', 'Paris']\n",
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n",
      "No prices found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/121082119.py:27: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/121082119.py:35: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/121082119.py:61: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  price_tags = soup.find_all('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n"
     ]
    }
   ],
   "source": [
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_school_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def extract_course_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "        # Extract course prices\n",
    "        price_tags = soup.find_all('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap')\n",
    "        prices = []\n",
    "        for tag in price_tags:\n",
    "            if 'Cost' in tag.get_text(strip=True):\n",
    "                price_element = tag.find_next('td')\n",
    "                if price_element:\n",
    "                    prices.append(price_element.get_text(strip=True))\n",
    "                else:\n",
    "                    prices.append(\"N/A\")\n",
    "\n",
    "        if prices:\n",
    "            print(f\"Course Prices: {prices}\")\n",
    "        else:\n",
    "            print(\"No prices found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83193345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n",
      "Cost row not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1618387630.py:17: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  price_row = soup.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def extract_course_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "        # Extract course prices\n",
    "        price_row = soup.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n",
    "        if price_row:\n",
    "            price_element = price_row.find_next('td')\n",
    "            if price_element:\n",
    "                price = price_element.get_text(strip=True)\n",
    "                print(f\"Course Price: {price}\")\n",
    "            else:\n",
    "                print(\"No price found.\")\n",
    "        else:\n",
    "            print(\"Cost row not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_course_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66542b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n",
      "No cost information found.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def extract_course_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "        # Find the table containing course details\n",
    "        details_table = soup.find('table', class_='table-auto text-sm text-gray-dark m-4')\n",
    "        if details_table:\n",
    "            # Find the row with the cost information\n",
    "            cost_row = details_table.find('tr', class_='align-text-top').find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap')\n",
    "            if cost_row:\n",
    "                # Extract the price\n",
    "                price = cost_row.find_next('td').get_text(strip=True)\n",
    "                print(f\"Course Price: {price}\")\n",
    "            else:\n",
    "                print(\"No cost information found.\")\n",
    "        else:\n",
    "            print(\"Details table not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_course_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61975b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n",
      "Cost label not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/2390977219.py:23: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  cost_label = cost_row.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def extract_course_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "        # Find the table containing course details\n",
    "        details_table = soup.find('table', class_='table-auto text-sm text-gray-dark m-4')\n",
    "        if details_table:\n",
    "            # Find the row with the cost information\n",
    "            cost_row = details_table.find('tr', class_='align-text-top')\n",
    "            if cost_row:\n",
    "                # Look for the \"Cost\" label and extract the corresponding value\n",
    "                cost_label = cost_row.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', text='Cost')\n",
    "                if cost_label:\n",
    "                    cost_value = cost_label.find_next('td').get_text(strip=True)\n",
    "                    print(f\"Course Price: {cost_value}\")\n",
    "                else:\n",
    "                    print(\"Cost label not found.\")\n",
    "            else:\n",
    "                print(\"No cost information found.\")\n",
    "        else:\n",
    "            print(\"Details table not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_course_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1a2bcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n",
      "No cost information found.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def extract_course_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "        # Find the table containing course details\n",
    "        details_table = soup.find('table', class_='table-auto text-sm text-gray-dark m-4')\n",
    "        if details_table:\n",
    "            # Iterate through all rows in the details table\n",
    "            for row in details_table.find_all('tr', class_='align-text-top'):\n",
    "                # Look for the \"Cost\" label within the row\n",
    "                cost_label = row.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', string='Cost')\n",
    "                if cost_label:\n",
    "                    # Extract the corresponding value\n",
    "                    cost_value = cost_label.find_next('td').get_text(strip=True)\n",
    "                    print(f\"Course Price: {cost_value}\")\n",
    "                    break  # Stop iterating if cost information is found\n",
    "            else:\n",
    "                print(\"No cost information found.\")\n",
    "        else:\n",
    "            print(\"Details table not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_course_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "045997e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n",
      "Cost information not found.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def extract_course_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "        # Find the table containing course details\n",
    "        details_table = soup.find('table', class_='table-auto text-sm text-gray-dark m-4')\n",
    "        if details_table:\n",
    "            # Search for the \"Cost\" label within the table\n",
    "            cost_label = details_table.find('td', class_='font-semibold md:text-right md:p-2 whitespace-nowrap', string='Cost')\n",
    "            if cost_label:\n",
    "                # Extract the corresponding value from the next sibling element\n",
    "                cost_value = cost_label.find_next('td').get_text(strip=True)\n",
    "                print(f\"Course Price: {cost_value}\")\n",
    "            else:\n",
    "                print(\"Cost information not found.\")\n",
    "        else:\n",
    "            print(\"Details table not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_course_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e6f85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Names: ['Cyber Security Bootcamp (Full-time)', 'Cyber Security Bootcamp (Part-time)', 'Data Analytics Bootcamp (Full-time)', 'Data Analytics Bootcamp (Part-Time)', 'UX/UI Design Bootcamp (Full-Time)', 'UX/UI Design Bootcamp (Part-Time)', 'Web Development Bootcamp (Full-time)', 'Web Development Bootcamp (Part-Time)']\n",
      "Number of reviews: 1070\n",
      "Cities: ['Amsterdam', 'Barcelona', 'Berlin', 'Lisbon', 'Madrid', 'Miami', 'Online', 'Paris']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/2283583567.py:27: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re  # Import the regular expression module\n",
    "\n",
    "def extract_course_info(html_content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "            print(f\"Course Names: {course_names}\")\n",
    "        else:\n",
    "            print(\"No course titles found.\")\n",
    "\n",
    "        # Extract number of reviews and remove the 'Reviews' part\n",
    "        reviews_span = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if reviews_span:\n",
    "            reviews_text = reviews_span.get_text(strip=True)\n",
    "            reviews_count = re.search(r'\\d+', reviews_text).group()\n",
    "            print(f\"Number of reviews: {reviews_count}\")\n",
    "        else:\n",
    "            print(\"Span tag for reviews not found.\")\n",
    "        \n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                    print(f\"Cities: {cities_list}\")\n",
    "                else:\n",
    "                    print(\"No cities found.\")\n",
    "            else:\n",
    "                print(\"Cities div not found.\")\n",
    "        else:\n",
    "            print(\"Locations div not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "\n",
    "# Example URL for coursereport.com\n",
    "url = 'https://www.coursereport.com/schools/ironhack'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "    extract_course_info(html_content)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01fb94bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/3766019849.py:26: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/3766019849.py:43: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Failed to extract data for ironhack\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Failed to extract data for app-academy\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Failed to extract data for springboard\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Failed to extract data for le-wagon\n",
      "\n",
      "Merged Courses DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Merged Locations DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Merged Reviews DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_course_info(html_content, school, school_id):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "        else:\n",
    "            course_names = []\n",
    "\n",
    "        # Extract number of reviews and remove the 'Reviews' part\n",
    "        reviews_span = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if reviews_span:\n",
    "            reviews_text = reviews_span.get_text(strip=True)\n",
    "            reviews_count = re.search(r'\\d+', reviews_text).group()\n",
    "        else:\n",
    "            reviews_count = None\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                else:\n",
    "                    cities_list = []\n",
    "            else:\n",
    "                cities_list = []\n",
    "        else:\n",
    "            cities_list = []\n",
    "\n",
    "        # Extract reviews information\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            average_rating = average_rating_span.find_next('span', class_='text-base').get_text(strip=True)\n",
    "        else:\n",
    "            average_rating = None\n",
    "\n",
    "        # Create Reviews DataFrame\n",
    "        reviews_df = pd.DataFrame({\n",
    "            'Rating': [average_rating] * len(course_names),\n",
    "            'ReviewsCount': [reviews_count] * len(course_names),\n",
    "            'School': [school] * len(course_names),\n",
    "            'SchoolID': [school_id] * len(course_names),\n",
    "        })\n",
    "\n",
    "        # Create Courses DataFrame\n",
    "        courses_df = pd.DataFrame({\n",
    "            'CourseName': course_names,\n",
    "            'School': [school] * len(course_names),\n",
    "            'SchoolID': [school_id] * len(course_names),\n",
    "        })\n",
    "\n",
    "        # Create Locations DataFrame\n",
    "        locations_df = pd.DataFrame({\n",
    "            'City': cities_list,\n",
    "            'School': [school] * len(cities_list),\n",
    "            'SchoolID': [school_id] * len(cities_list),\n",
    "        })\n",
    "\n",
    "        return {'Courses': courses_df, 'Locations': locations_df, 'Reviews': reviews_df}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define a dictionary to store dataframes for each school\n",
    "school_data_dict = {}\n",
    "\n",
    "# List of schools and their IDs\n",
    "schools = {\n",
    "    'ironhack': 10828,\n",
    "    'app-academy': 10525,\n",
    "    'springboard': 11035,\n",
    "    'le-wagon': 10868,\n",
    "    # Add more schools as needed\n",
    "}\n",
    "\n",
    "for school, school_id in schools.items():\n",
    "    # Example URL for coursereport.com\n",
    "    url = f'https://www.coursereport.com/schools/{school}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        extracted_data = extract_course_info(html_content, school, school_id)\n",
    "\n",
    "        if extracted_data:\n",
    "            # Add extracted data to the dictionary\n",
    "            school_data_dict[school] = extracted_data\n",
    "        else:\n",
    "            print(f\"Failed to extract data for {school}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {school}. Status code: {response.status_code}\")\n",
    "\n",
    "# Create an empty dataframe to store the merged data\n",
    "merged_courses_df = pd.DataFrame()\n",
    "merged_locations_df = pd.DataFrame()\n",
    "merged_reviews_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the school_data_dict and merge the dataframes\n",
    "for school, dataframes in school_data_dict.items():\n",
    "    # Merge Courses DataFrames\n",
    "    merged_courses_df = pd.concat([merged_courses_df, dataframes['Courses']], ignore_index=True)\n",
    "\n",
    "    # Merge Locations DataFrames\n",
    "    merged_locations_df = pd.concat([merged_locations_df, dataframes['Locations']], ignore_index=True)\n",
    "\n",
    "    # Merge Reviews DataFrames\n",
    "    if 'Reviews' in dataframes:\n",
    "        merged_reviews_df = pd.concat([merged_reviews_df, dataframes['Reviews']], ignore_index=True)\n",
    "\n",
    "# Display the merged dataframes\n",
    "print(\"\\nMerged Courses DataFrame:\")\n",
    "print(merged_courses_df)\n",
    "\n",
    "print(\"\\nMerged Locations DataFrame:\")\n",
    "print(merged_locations_df)\n",
    "\n",
    "print(\"\\nMerged Reviews DataFrame:\")\n",
    "print(merged_reviews_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17de378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c4bb7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1295676829.py:41: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1295676829.py:58: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "\n",
      "Merged Courses DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Merged Locations DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Merged Reviews DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_school_data(school, school_id):\n",
    "    # Construct URL\n",
    "    url = f'https://www.coursereport.com/schools/{school}'\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        return extract_dataframes(html_content, school, school_id)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return None, None, None\n",
    "\n",
    "def extract_dataframes(html_content, school, school_id):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "        else:\n",
    "            course_names = []\n",
    "\n",
    "        # Extract number of reviews and remove the 'Reviews' part\n",
    "        reviews_span = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if reviews_span:\n",
    "            reviews_text = reviews_span.get_text(strip=True)\n",
    "            reviews_count = re.search(r'\\d+', reviews_text).group()\n",
    "        else:\n",
    "            reviews_count = None\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                else:\n",
    "                    cities_list = []\n",
    "            else:\n",
    "                cities_list = []\n",
    "        else:\n",
    "            cities_list = []\n",
    "\n",
    "        # Extract reviews information\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            average_rating = average_rating_span.find_next('span', class_='text-base').get_text(strip=True)\n",
    "        else:\n",
    "            average_rating = None\n",
    "\n",
    "        # Create Reviews DataFrame\n",
    "        reviews_df = pd.DataFrame({\n",
    "            'Rating': [average_rating] * len(course_names),\n",
    "            'ReviewsCount': [reviews_count] * len(course_names),\n",
    "            'School': [school] * len(course_names),\n",
    "            'SchoolID': [school_id] * len(course_names),\n",
    "        })\n",
    "\n",
    "        # Create Courses DataFrame\n",
    "        courses_df = pd.DataFrame({\n",
    "            'CourseName': course_names,\n",
    "            'School': [school] * len(course_names),\n",
    "            'SchoolID': [school_id] * len(course_names),\n",
    "        })\n",
    "\n",
    "        # Create Locations DataFrame\n",
    "        locations_df = pd.DataFrame({\n",
    "            'City': cities_list,\n",
    "            'School': [school] * len(cities_list),\n",
    "            'SchoolID': [school_id] * len(cities_list),\n",
    "        })\n",
    "\n",
    "        return courses_df, locations_df, reviews_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Example usage:\n",
    "school_data_dict = {}\n",
    "\n",
    "schools = {   \n",
    "    'ironhack' : 10828,\n",
    "    'app-academy' : 10525,\n",
    "    'springboard' : 11035,\n",
    "    'le-wagon' : 10868,\n",
    "}\n",
    "\n",
    "for school, school_id in schools.items():\n",
    "    courses_df, locations_df, reviews_df = scrape_school_data(school, school_id)\n",
    "    school_data_dict[school] = {'Courses': courses_df, 'Locations': locations_df, 'Reviews': reviews_df}\n",
    "\n",
    "# Create an empty dataframe to store the merged data\n",
    "merged_courses_df = pd.DataFrame()\n",
    "merged_locations_df = pd.DataFrame()\n",
    "merged_reviews_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the school_data_dict and merge the dataframes\n",
    "for school, dataframes in school_data_dict.items():\n",
    "    # Merge Courses DataFrames\n",
    "    merged_courses_df = pd.concat([merged_courses_df, dataframes['Courses']], ignore_index=True)\n",
    "\n",
    "    # Merge Locations DataFrames\n",
    "    merged_locations_df = pd.concat([merged_locations_df, dataframes['Locations']], ignore_index=True)\n",
    "\n",
    "    # Merge Reviews DataFrames\n",
    "    if 'Reviews' in dataframes:\n",
    "        merged_reviews_df = pd.concat([merged_reviews_df, dataframes['Reviews']], ignore_index=True)\n",
    "\n",
    "# Display the merged dataframes\n",
    "print(\"\\nMerged Courses DataFrame:\")\n",
    "print(merged_courses_df)\n",
    "\n",
    "print(\"\\nMerged Locations DataFrame:\")\n",
    "print(merged_locations_df)\n",
    "\n",
    "print(\"\\nMerged Reviews DataFrame:\")\n",
    "print(merged_reviews_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db1c3483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "Error during parsing: 'NoneType' object has no attribute 'get_text'\n",
      "\n",
      "Merged Courses DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Merged Locations DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Merged Reviews DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_school_data(school, school_id):\n",
    "    # Construct URL\n",
    "    url = f'https://www.coursereport.com/schools/{school}'\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        return extract_dataframes(html_content, school, school_id)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return None, None, None\n",
    "\n",
    "def extract_dataframes(html_content, school, school_id):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "\n",
    "        # Extract number of reviews and remove the 'Reviews' part\n",
    "        reviews_span = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        reviews_count = re.search(r'\\d+', reviews_span.get_text(strip=True)).group() if reviews_span else None\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', string='Locations')\n",
    "        cities_div = locations_div.find_next('div') if locations_div else None\n",
    "        cities = cities_div.find_all('a') if cities_div else []\n",
    "        cities_list = [city.get_text(strip=True) for city in cities]\n",
    "\n",
    "        # Extract reviews information\n",
    "        average_rating_span = soup.find('span', string='Average Rating')\n",
    "        average_rating = average_rating_span.find_next('span', class_='text-base').get_text(strip=True) if average_rating_span else None\n",
    "\n",
    "        # Create Reviews DataFrame\n",
    "        reviews_df = pd.DataFrame({\n",
    "            'Rating': [average_rating] * len(course_names),\n",
    "            'ReviewsCount': [reviews_count] * len(course_names),\n",
    "            'School': [school] * len(course_names),\n",
    "            'SchoolID': [school_id] * len(course_names),\n",
    "        })\n",
    "\n",
    "        # Create Courses DataFrame\n",
    "        courses_df = pd.DataFrame({\n",
    "            'CourseName': course_names,\n",
    "            'School': [school] * len(course_names),\n",
    "            'SchoolID': [school_id] * len(course_names),\n",
    "        })\n",
    "\n",
    "        # Create Locations DataFrame\n",
    "        locations_df = pd.DataFrame({\n",
    "            'City': cities_list,\n",
    "            'School': [school] * len(cities_list),\n",
    "            'SchoolID': [school_id] * len(cities_list),\n",
    "        })\n",
    "\n",
    "        return courses_df, locations_df, reviews_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Example usage:\n",
    "school_data_dict = {}\n",
    "\n",
    "schools = {   \n",
    "    'ironhack' : 10828,\n",
    "    'app-academy' : 10525,\n",
    "    'springboard' : 11035,\n",
    "    'le-wagon' : 10868,\n",
    "}\n",
    "\n",
    "for school, school_id in schools.items():\n",
    "    courses_df, locations_df, reviews_df = scrape_school_data(school, school_id)\n",
    "    school_data_dict[school] = {'Courses': courses_df, 'Locations': locations_df, 'Reviews': reviews_df}\n",
    "\n",
    "# Create an empty dataframe to store the merged data\n",
    "merged_courses_df = pd.DataFrame()\n",
    "merged_locations_df = pd.DataFrame()\n",
    "merged_reviews_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the school_data_dict and merge the dataframes\n",
    "for school, dataframes in school_data_dict.items():\n",
    "    # Merge Courses DataFrames\n",
    "    if dataframes['Courses'] is not None:\n",
    "        merged_courses_df = pd.concat([merged_courses_df, dataframes['Courses']], ignore_index=True)\n",
    "\n",
    "    # Merge Locations DataFrames\n",
    "    if dataframes['Locations'] is not None:\n",
    "        merged_locations_df = pd.concat([merged_locations_df, dataframes['Locations']], ignore_index=True)\n",
    "\n",
    "    # Merge Reviews DataFrames\n",
    "    if 'Reviews' in dataframes and dataframes['Reviews'] is not None:\n",
    "        merged_reviews_df = pd.concat([merged_reviews_df, dataframes['Reviews']], ignore_index=True)\n",
    "\n",
    "# Display the merged dataframes\n",
    "print(\"\\nMerged Courses DataFrame:\")\n",
    "print(merged_courses_df)\n",
    "\n",
    "print(\"\\nMerged Locations DataFrame:\")\n",
    "print(merged_locations_df)\n",
    "\n",
    "print(\"\\nMerged Reviews DataFrame:\")\n",
    "print(merged_reviews_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb4be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da3c0628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during parsing: If using all scalar values, you must pass an index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1176437839.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/1176437839.py:45: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 81\u001b[0m\n\u001b[1;32m     75\u001b[0m schools \u001b[38;5;241m=\u001b[39m {   \n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mironhack\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m10828\u001b[39m,\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapp-academy\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m10525\u001b[39m,\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspringboard\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m11035\u001b[39m,\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mle-wagon\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m10868\u001b[39m,}\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m school, school_id \u001b[38;5;129;01min\u001b[39;00m schools\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 81\u001b[0m     courses_df, locations_df,reviews_df \u001b[38;5;241m=\u001b[39m scrape_school_data(school, school_id)\n\u001b[1;32m     82\u001b[0m     school_data_dict[school] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCourses\u001b[39m\u001b[38;5;124m'\u001b[39m: courses_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m'\u001b[39m: locations_df,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReviews\u001b[39m\u001b[38;5;124m'\u001b[39m:reviews_df}\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Print the dictionary\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def scrape_school_data(school, school_id):\n",
    "    # Construct URL\n",
    "    url = f'https://www.coursereport.com/schools/{school}'\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        return extract_dataframes(html_content, school, school_id)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_dataframes(html_content, school, school_id):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "        else:\n",
    "            course_names = []\n",
    "\n",
    "        # Extract number of reviews and remove the 'Reviews' part\n",
    "        reviews_span = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if reviews_span:\n",
    "            reviews_text = reviews_span.get_text(strip=True)\n",
    "            reviews_count = re.search(r'\\d+', reviews_text).group()\n",
    "        else:\n",
    "            reviews_count = None\n",
    "        \n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                else:\n",
    "                    cities_list = []\n",
    "            else:\n",
    "                cities_list = []\n",
    "        else:\n",
    "            cities_list = []\n",
    "\n",
    "        # Create dataframes\n",
    "        courses_df = pd.DataFrame({'CourseName': course_names, 'School': school, 'SchoolID': school_id})\n",
    "        locations_df = pd.DataFrame({'City': cities_list, 'School': school, 'SchoolID': school_id})\n",
    "        reviews_df=pd.DataFrame({'Reviews': reviews_count, 'Rating':rating, 'School': school, 'SchoolID': school_id})\n",
    "\n",
    "        return courses_df, locations_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Example usage:\n",
    "school_data_dict = {}\n",
    "\n",
    "schools = {   \n",
    "    'ironhack' : 10828,\n",
    "    'app-academy' : 10525,\n",
    "    'springboard' : 11035,\n",
    "    'le-wagon' : 10868,}\n",
    "for school, school_id in schools.items():\n",
    "    courses_df, locations_df,reviews_df = scrape_school_data(school, school_id)\n",
    "    school_data_dict[school] = {'Courses': courses_df, 'Locations': locations_df,'Reviews':reviews_df}\n",
    "\n",
    "# Print the dictionary\n",
    "for school, dataframes in school_data_dict.items():\n",
    "    print(f\"\\nSchool: {school}\")\n",
    "    print(\"Courses DataFrame:\")\n",
    "    print(dataframes['Courses'])\n",
    "\n",
    "    print(\"\\nLocations DataFrame:\")\n",
    "    print(dataframes['Locations'])\n",
    "    \n",
    "    print(\"\\Reviews DataFrame:\")\n",
    "    print(dataframes['Reviews'])\n",
    "    \n",
    "    \n",
    "    \n",
    "# Create an empty dataframe to store the merged data\n",
    "merged_courses_df = pd.DataFrame()\n",
    "merged_locations_df = pd.DataFrame()\n",
    "merged_reviews_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the school_data_dict and merge the dataframes\n",
    "for school, dataframes in school_data_dict.items():\n",
    "    # Merge Courses DataFrames\n",
    "    merged_courses_df = pd.concat([merged_courses_df, dataframes['Courses']], ignore_index=True)\n",
    "\n",
    "    # Merge Locations DataFrames\n",
    "    merged_locations_df = pd.concat([merged_locations_df, dataframes['Locations']], ignore_index=True)\n",
    "\n",
    "    # Merge Reviews DataFrames\n",
    "    if 'Reviews' in dataframes:\n",
    "        merged_reviews_df = pd.concat([merged_reviews_df, dataframes['Reviews']], ignore_index=True)\n",
    "\n",
    "# Display the merged dataframes\n",
    "print(\"\\nMerged Courses DataFrame:\")\n",
    "print(merged_courses_df)\n",
    "\n",
    "print(\"\\nMerged Locations DataFrame:\")\n",
    "print(merged_locations_df)\n",
    "\n",
    "print(\"\\nMerged Reviews DataFrame:\")\n",
    "print(merged_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ea1eb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:45: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:45: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:45: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:45: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:45: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:45: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "School: ironhack\n",
      "Courses DataFrame:\n",
      "                             CourseName    School  SchoolID\n",
      "0   Cyber Security Bootcamp (Full-time)  ironhack     10828\n",
      "1   Cyber Security Bootcamp (Part-time)  ironhack     10828\n",
      "2   Data Analytics Bootcamp (Full-time)  ironhack     10828\n",
      "3   Data Analytics Bootcamp (Part-Time)  ironhack     10828\n",
      "4     UX/UI Design Bootcamp (Full-Time)  ironhack     10828\n",
      "5     UX/UI Design Bootcamp (Part-Time)  ironhack     10828\n",
      "6  Web Development Bootcamp (Full-time)  ironhack     10828\n",
      "7  Web Development Bootcamp (Part-Time)  ironhack     10828\n",
      "\n",
      "Locations DataFrame:\n",
      "        City    School  SchoolID\n",
      "0  Amsterdam  ironhack     10828\n",
      "1  Barcelona  ironhack     10828\n",
      "2     Berlin  ironhack     10828\n",
      "3     Lisbon  ironhack     10828\n",
      "4     Madrid  ironhack     10828\n",
      "5      Miami  ironhack     10828\n",
      "6     Online  ironhack     10828\n",
      "7      Paris  ironhack     10828\n",
      "\\Reviews DataFrame:\n",
      "  Reviews Rating    School  SchoolID\n",
      "0    1070   4.79  ironhack     10828\n",
      "\n",
      "School: app-academy\n",
      "Courses DataFrame:\n",
      "                                          CourseName       School  SchoolID\n",
      "0                16-Week In-Person New York Bootcamp  app-academy     10525\n",
      "1  16-Week Online Full-Time Accelerated Software ...  app-academy     10525\n",
      "2  24-Week Online Software Engineering Program (F...  app-academy     10525\n",
      "3  48-week Online Software Engineering Program (P...  app-academy     10525\n",
      "4                               4-week Bootcamp Prep  app-academy     10525\n",
      "5                  Bootcamp Prep Self-Paced (Online)  app-academy     10525\n",
      "6                             Self-paced Open Course  app-academy     10525\n",
      "\n",
      "Locations DataFrame:\n",
      "            City       School  SchoolID\n",
      "0  New York City  app-academy     10525\n",
      "1         Online  app-academy     10525\n",
      "\\Reviews DataFrame:\n",
      "  Reviews Rating       School  SchoolID\n",
      "0    1144   4.67  app-academy     10525\n",
      "\n",
      "School: springboard\n",
      "Courses DataFrame:\n",
      "                                CourseName       School  SchoolID\n",
      "0              Cyber Security Career Track  springboard     11035\n",
      "1              Data Analytics Career Track  springboard     11035\n",
      "2                Data Science Career Track  springboard     11035\n",
      "3           Data Science Career Track Prep  springboard     11035\n",
      "4           Introduction to Data Analytics  springboard     11035\n",
      "5                   Introduction to Design  springboard     11035\n",
      "6        Software Engineering Career Track  springboard     11035\n",
      "7   Software Engineering Career Track Prep  springboard     11035\n",
      "8                  Tech Sales Career Track  springboard     11035\n",
      "9              UI / UX Design Career Track  springboard     11035\n",
      "10                         UX Career Track  springboard     11035\n",
      "\n",
      "Locations DataFrame:\n",
      "     City       School  SchoolID\n",
      "0  Online  springboard     11035\n",
      "\\Reviews DataFrame:\n",
      "  Reviews Rating       School  SchoolID\n",
      "0    1511   4.63  springboard     11035\n",
      "\n",
      "School: le-wagon\n",
      "Courses DataFrame:\n",
      "                                       CourseName    School  SchoolID\n",
      "0                         Data Analytics Bootcamp  le-wagon     10868\n",
      "1                  Data Analytics Bootcamp Online  le-wagon     10868\n",
      "2          Data Analytics Essentials Skill Course  le-wagon     10868\n",
      "3                       Data Engineering Bootcamp  le-wagon     10868\n",
      "4                Data Engineering Bootcamp Online  le-wagon     10868\n",
      "5          Data Science & AI Bootcamp - Full-time  le-wagon     10868\n",
      "6               Data Science & AI Bootcamp Online  le-wagon     10868\n",
      "7          Data Science & AI Bootcamp - Part-time  le-wagon     10868\n",
      "8   Data Science & AI Bootcamp - Part-time Online  le-wagon     10868\n",
      "9           Growth & Data Automation Skill Course  le-wagon     10868\n",
      "10         Python & Machine Learning Skill Course  le-wagon     10868\n",
      "11          Web Analytics & Tracking Skill Course  le-wagon     10868\n",
      "12           Web Development Bootcamp - Full-time  le-wagon     10868\n",
      "13                Web Development Bootcamp Online  le-wagon     10868\n",
      "14           Web Development Bootcamp - Part-time  le-wagon     10868\n",
      "15    Web Development Bootcamp - Part-time Online  le-wagon     10868\n",
      "\n",
      "Locations DataFrame:\n",
      "              City    School  SchoolID\n",
      "0        Amsterdam  le-wagon     10868\n",
      "1             Bali  le-wagon     10868\n",
      "2        Barcelona  le-wagon     10868\n",
      "3           Berlin  le-wagon     10868\n",
      "4         Bordeaux  le-wagon     10868\n",
      "5         Brussels  le-wagon     10868\n",
      "6     Buenos Aires  le-wagon     10868\n",
      "7        Cape Town  le-wagon     10868\n",
      "8       Casablanca  le-wagon     10868\n",
      "9          Cologne  le-wagon     10868\n",
      "10           Dubai  le-wagon     10868\n",
      "11        Lausanne  le-wagon     10868\n",
      "12           Lille  le-wagon     10868\n",
      "13          Lisbon  le-wagon     10868\n",
      "14          London  le-wagon     10868\n",
      "15            Lyon  le-wagon     10868\n",
      "16          Madrid  le-wagon     10868\n",
      "17       Marseille  le-wagon     10868\n",
      "18       Mauritius  le-wagon     10868\n",
      "19       Melbourne  le-wagon     10868\n",
      "20     Mexico City  le-wagon     10868\n",
      "21        Montreal  le-wagon     10868\n",
      "22          Munich  le-wagon     10868\n",
      "23          Nantes  le-wagon     10868\n",
      "24            Nice  le-wagon     10868\n",
      "25          Online  le-wagon     10868\n",
      "26           Paris  le-wagon     10868\n",
      "27           Porto  le-wagon     10868\n",
      "28          Rennes  le-wagon     10868\n",
      "29  Rio de Janeiro  le-wagon     10868\n",
      "30        Santiago  le-wagon     10868\n",
      "31       Sao Paulo  le-wagon     10868\n",
      "32        Shanghai  le-wagon     10868\n",
      "33       Singapore  le-wagon     10868\n",
      "34          Sydney  le-wagon     10868\n",
      "35           Tokyo  le-wagon     10868\n",
      "36        Toulouse  le-wagon     10868\n",
      "37          Zurich  le-wagon     10868\n",
      "\\Reviews DataFrame:\n",
      "  Reviews Rating    School  SchoolID\n",
      "0    3062   4.96  le-wagon     10868\n",
      "\n",
      "School: brainstation\n",
      "Courses DataFrame:\n",
      "                                          CourseName        School  SchoolID\n",
      "0              Artificial Intelligence Course Online  brainstation     10571\n",
      "1                      Cybersecurity Bootcamp Online  brainstation     10571\n",
      "2                        Cybersecurity Course Online  brainstation     10571\n",
      "3                              Data Analytics Course  brainstation     10571\n",
      "4                       Data Analytics Course Online  brainstation     10571\n",
      "5                              Data Science Bootcamp  brainstation     10571\n",
      "6                                Data Science Course  brainstation     10571\n",
      "7                         Data Science Course Online  brainstation     10571\n",
      "8                    Design Leadership Course Online  brainstation     10571\n",
      "9                           Digital Marketing Course  brainstation     10571\n",
      "10                   Digital Marketing Course Online  brainstation     10571\n",
      "11            Full-Time Data Science Bootcamp Online  brainstation     10571\n",
      "12    Full-Time Software Engineering Bootcamp Online  brainstation     10571\n",
      "13  Full-Time User Experience Design Bootcamp Online  brainstation     10571\n",
      "14         Full-Time Web Development Bootcamp Online  brainstation     10571\n",
      "15                Marketing Leadership Course Online  brainstation     10571\n",
      "16            Part-Time Data Science Bootcamp Online  brainstation     10571\n",
      "17    Part-Time Software Engineering Bootcamp Online  brainstation     10571\n",
      "18  Part-Time User Experience Design Bootcamp Online  brainstation     10571\n",
      "19         Part-Time Web Development Bootcamp Online  brainstation     10571\n",
      "20                  Product Leadership Course Online  brainstation     10571\n",
      "21                         Product Management Course  brainstation     10571\n",
      "22                  Product Management Course Online  brainstation     10571\n",
      "23                                            Python  brainstation     10571\n",
      "24                    Search Engine Marketing Course  brainstation     10571\n",
      "25                     Social Media Marketing Course  brainstation     10571\n",
      "26                     Software Engineering Bootcamp  brainstation     10571\n",
      "27                   User Experience Design Bootcamp  brainstation     10571\n",
      "28                     User Experience Design Course  brainstation     10571\n",
      "29              User Experience Design Course Online  brainstation     10571\n",
      "30               User Interface Design Course Online  brainstation     10571\n",
      "31                          Web Development Bootcamp  brainstation     10571\n",
      "32                     Web Development Course Online  brainstation     10571\n",
      "\n",
      "Locations DataFrame:\n",
      "            City        School  SchoolID\n",
      "0         London  brainstation     10571\n",
      "1          Miami  brainstation     10571\n",
      "2  New York City  brainstation     10571\n",
      "3         Online  brainstation     10571\n",
      "4        Toronto  brainstation     10571\n",
      "5      Vancouver  brainstation     10571\n",
      "\\Reviews DataFrame:\n",
      "  Reviews Rating        School  SchoolID\n",
      "0    1929   4.67  brainstation     10571\n",
      "\n",
      "School: nucamp\n",
      "Courses DataFrame:\n",
      "                                          CourseName  School  SchoolID\n",
      "0              Back End, SQL, and DevOps with Python  nucamp     10923\n",
      "1               Front End Web and Mobile Development  nucamp     10923\n",
      "2  Full Stack Web and Mobile Application Development  nucamp     10923\n",
      "3                               Job Hunting Bootcamp  nucamp     10923\n",
      "4                       Web Development Fundamentals  nucamp     10923\n",
      "\n",
      "Locations DataFrame:\n",
      "             City  School  SchoolID\n",
      "0         Atlanta  nucamp     10923\n",
      "1       Baltimore  nucamp     10923\n",
      "2      Bellingham  nucamp     10923\n",
      "3      Charleston  nucamp     10923\n",
      "4       Charlotte  nucamp     10923\n",
      "5     Chattanooga  nucamp     10923\n",
      "6          Dallas  nucamp     10923\n",
      "7         Detroit  nucamp     10923\n",
      "8          Irvine  nucamp     10923\n",
      "9     Kansas City  nucamp     10923\n",
      "10      Las Vegas  nucamp     10923\n",
      "11    Los Angeles  nucamp     10923\n",
      "12     Marysville  nucamp     10923\n",
      "13    Minneapolis  nucamp     10923\n",
      "14      Nashville  nucamp     10923\n",
      "15        Oakland  nucamp     10923\n",
      "16         Online  nucamp     10923\n",
      "17  Orange County  nucamp     10923\n",
      "18        Orlando  nucamp     10923\n",
      "19   Philadelphia  nucamp     10923\n",
      "20     Pittsburgh  nucamp     10923\n",
      "21           Reno  nucamp     10923\n",
      "22      Riverside  nucamp     10923\n",
      "23     Sacramento  nucamp     10923\n",
      "24    San Antonio  nucamp     10923\n",
      "25      San Diego  nucamp     10923\n",
      "26  San Francisco  nucamp     10923\n",
      "27       San Jose  nucamp     10923\n",
      "28        Seattle  nucamp     10923\n",
      "29        Spokane  nucamp     10923\n",
      "30       St. Paul  nucamp     10923\n",
      "31         Tacoma  nucamp     10923\n",
      "32     Washington  nucamp     10923\n",
      "\\Reviews DataFrame:\n",
      "  Reviews Rating  School  SchoolID\n",
      "0    1781   4.74  nucamp     10923\n",
      "\n",
      "School: shecodes\n",
      "Courses DataFrame:\n",
      "        CourseName    School  SchoolID\n",
      "0  SheCodes Basics  shecodes     11014\n",
      "1     SheCodes Max  shecodes     11014\n",
      "2    SheCodes Plus  shecodes     11014\n",
      "3     SheCodes Pro  shecodes     11014\n",
      "\n",
      "Locations DataFrame:\n",
      "     City    School  SchoolID\n",
      "0  Online  shecodes     11014\n",
      "\\Reviews DataFrame:\n",
      "  Reviews Rating    School  SchoolID\n",
      "0    1316   4.97  shecodes     11014\n",
      "\n",
      "Merged Courses DataFrame:\n",
      "                             CourseName    School  SchoolID\n",
      "0   Cyber Security Bootcamp (Full-time)  ironhack     10828\n",
      "1   Cyber Security Bootcamp (Part-time)  ironhack     10828\n",
      "2   Data Analytics Bootcamp (Full-time)  ironhack     10828\n",
      "3   Data Analytics Bootcamp (Part-Time)  ironhack     10828\n",
      "4     UX/UI Design Bootcamp (Full-Time)  ironhack     10828\n",
      "..                                  ...       ...       ...\n",
      "79         Web Development Fundamentals    nucamp     10923\n",
      "80                      SheCodes Basics  shecodes     11014\n",
      "81                         SheCodes Max  shecodes     11014\n",
      "82                        SheCodes Plus  shecodes     11014\n",
      "83                         SheCodes Pro  shecodes     11014\n",
      "\n",
      "[84 rows x 3 columns]\n",
      "\n",
      "Merged Locations DataFrame:\n",
      "          City    School  SchoolID\n",
      "0    Amsterdam  ironhack     10828\n",
      "1    Barcelona  ironhack     10828\n",
      "2       Berlin  ironhack     10828\n",
      "3       Lisbon  ironhack     10828\n",
      "4       Madrid  ironhack     10828\n",
      "..         ...       ...       ...\n",
      "84     Spokane    nucamp     10923\n",
      "85    St. Paul    nucamp     10923\n",
      "86      Tacoma    nucamp     10923\n",
      "87  Washington    nucamp     10923\n",
      "88      Online  shecodes     11014\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "\n",
      "Merged Reviews DataFrame:\n",
      "  Reviews Rating        School  SchoolID\n",
      "0    1070   4.79      ironhack     10828\n",
      "1    1144   4.67   app-academy     10525\n",
      "2    1511   4.63   springboard     11035\n",
      "3    3062   4.96      le-wagon     10868\n",
      "4    1929   4.67  brainstation     10571\n",
      "5    1781   4.74        nucamp     10923\n",
      "6    1316   4.97      shecodes     11014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  average_rating_span = soup.find('span', text='Average Rating')\n",
      "/var/folders/90/k9fypstn4y12th_l5jjxyxt00000gn/T/ipykernel_43365/958003403.py:45: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  locations_div = soup.find('div', class_='font-medium', text='Locations')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def scrape_school_data(school, school_id):\n",
    "    # Construct URL\n",
    "    url = f'https://www.coursereport.com/schools/{school}'\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        return extract_dataframes(html_content, school, school_id)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return None, None, None\n",
    "\n",
    "def extract_dataframes(html_content, school, school_id):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract course names\n",
    "        course_titles = soup.find_all('h3', class_='font-semibold text-lg md:text-xl my-4 md:my-0')\n",
    "        if course_titles:\n",
    "            course_names = [title.get_text(strip=True) for title in course_titles]\n",
    "        else:\n",
    "            course_names = []\n",
    "\n",
    "        # Extract number of reviews and remove the 'Reviews' part\n",
    "        reviews_span = soup.find('span', class_='text-orange-dark font-semibold')\n",
    "        if reviews_span:\n",
    "            reviews_text = reviews_span.get_text(strip=True)\n",
    "            reviews_count = re.search(r'\\d+', reviews_text).group()\n",
    "        else:\n",
    "            reviews_count = None\n",
    "        \n",
    "        # Extract average rating\n",
    "        average_rating_span = soup.find('span', text='Average Rating')\n",
    "        if average_rating_span:\n",
    "            rating = average_rating_span.find_next_sibling('span').get_text(strip=True)\n",
    "        else:\n",
    "            print(\"Average Rating not found.\")\n",
    "\n",
    "        # Extract locations\n",
    "        locations_div = soup.find('div', class_='font-medium', text='Locations')\n",
    "        if locations_div:\n",
    "            # Traverse to the next <div> containing cities\n",
    "            cities_div = locations_div.find_next('div')\n",
    "            if cities_div:\n",
    "                # Find <a> elements inside the cities_div\n",
    "                cities = cities_div.find_all('a')\n",
    "                if cities:\n",
    "                    cities_list = [city.get_text(strip=True) for city in cities]\n",
    "                else:\n",
    "                    cities_list = []\n",
    "            else:\n",
    "                cities_list = []\n",
    "        else:\n",
    "            cities_list = []\n",
    "\n",
    "        # Create dataframes\n",
    "        courses_df = pd.DataFrame({'CourseName': course_names, 'School': school, 'SchoolID': school_id})\n",
    "        locations_df = pd.DataFrame({'City': cities_list, 'School': school, 'SchoolID': school_id})\n",
    "        reviews_df = pd.DataFrame({'Reviews': [reviews_count], 'Rating': [rating], 'School': [school], 'SchoolID': [school_id]})\n",
    "\n",
    "        return courses_df, locations_df, reviews_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during parsing: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Example usage:\n",
    "school_data_dict = {}\n",
    "\n",
    "schools = {   \n",
    "    'ironhack': 10828,\n",
    "    'app-academy': 10525,\n",
    "    'springboard': 11035,\n",
    "    'le-wagon': 10868,\n",
    "    'brainstation':10571,\n",
    "    'nucamp':10923,\n",
    "    'shecodes':11014\n",
    "}\n",
    "for school, school_id in schools.items():\n",
    "    courses_df, locations_df, reviews_df = scrape_school_data(school, school_id)\n",
    "    school_data_dict[school] = {'Courses': courses_df, 'Locations': locations_df, 'Reviews': reviews_df}\n",
    "\n",
    "# Print the dictionary\n",
    "for school, dataframes in school_data_dict.items():\n",
    "    print(f\"\\nSchool: {school}\")\n",
    "    print(\"Courses DataFrame:\")\n",
    "    print(dataframes['Courses'])\n",
    "\n",
    "    print(\"\\nLocations DataFrame:\")\n",
    "    print(dataframes['Locations'])\n",
    "    \n",
    "    print(\"\\Reviews DataFrame:\")\n",
    "    print(dataframes['Reviews'])\n",
    "    \n",
    "    \n",
    "    \n",
    "# Create an empty dataframe to store the merged data\n",
    "merged_courses_df = pd.DataFrame()\n",
    "merged_locations_df = pd.DataFrame()\n",
    "merged_reviews_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the school_data_dict and merge the dataframes\n",
    "for school, dataframes in school_data_dict.items():\n",
    "    # Merge Courses DataFrames\n",
    "    if dataframes['Courses'] is not None:\n",
    "        merged_courses_df = pd.concat([merged_courses_df, dataframes['Courses']], ignore_index=True)\n",
    "\n",
    "    # Merge Locations DataFrames\n",
    "    if dataframes['Locations'] is not None:\n",
    "        merged_locations_df = pd.concat([merged_locations_df, dataframes['Locations']], ignore_index=True)\n",
    "\n",
    "    # Merge Reviews DataFrames\n",
    "    if 'Reviews' in dataframes and dataframes['Reviews'] is not None:\n",
    "        merged_reviews_df = pd.concat([merged_reviews_df, dataframes['Reviews']], ignore_index=True)\n",
    "\n",
    "# Display the merged dataframes\n",
    "print(\"\\nMerged Courses DataFrame:\")\n",
    "print(merged_courses_df)\n",
    "\n",
    "print(\"\\nMerged Locations DataFrame:\")\n",
    "print(merged_locations_df)\n",
    "\n",
    "print(\"\\nMerged Reviews DataFrame:\")\n",
    "print(merged_reviews_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb07df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
